{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e3fd80e-8990-44ef-90f1-b7247c178196",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Libraries and Authorisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1209867f-0c4d-4b92-8919-003af95fe8f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8ce410c5-5f52-4b7e-9600-f823994902c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from sources and Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3975bec0-913c-4ca9-a0b0-61ed2a4cc399",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ðŸ“‹ Import `packaging_weight` data from Google Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The original pipeline extracted this data from a Google Sheet, allowing the stakeholders to interactively update the source of data, otherwise missing from any certified table in the Data Warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7acd619-9b95-40da-900c-7e2415dc714b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---- Load demand data in a dataframe # packaging_weight_pd\n",
    "file_path = '/Users/fil/Documents/my_projects/packaging_licencing_fee/datasets/packaging_weight_pd_2024_11_20.csv'\n",
    "packaging_weight_pd = pd.read_csv(file_path) # Execute the query and load the result into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51e0db52-2b20-4132-ba96-7d97c698cf18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4972 entries, 0 to 4971\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sku                4972 non-null   object \n",
      " 1   has_packaging      4971 non-null   object \n",
      " 2   category           4504 non-null   object \n",
      " 3   unit_weight_grams  4451 non-null   float64\n",
      " 4   packaging_type     3701 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 194.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#describe the dataframe\n",
    "packaging_weight_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>has_packaging</th>\n",
       "      <th>category</th>\n",
       "      <th>unit_weight_grams</th>\n",
       "      <th>packaging_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alias-49384</td>\n",
       "      <td>yes</td>\n",
       "      <td>paper</td>\n",
       "      <td>0.6</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alias-49384</td>\n",
       "      <td>yes</td>\n",
       "      <td>plastic</td>\n",
       "      <td>26.0</td>\n",
       "      <td>thermoform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alias-79751</td>\n",
       "      <td>yes</td>\n",
       "      <td>paper</td>\n",
       "      <td>0.6</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alias-79751</td>\n",
       "      <td>yes</td>\n",
       "      <td>paper</td>\n",
       "      <td>0.6</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alias-79751</td>\n",
       "      <td>yes</td>\n",
       "      <td>plastic</td>\n",
       "      <td>8.0</td>\n",
       "      <td>flowpack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sku has_packaging category  unit_weight_grams packaging_type\n",
       "0  alias-49384           yes    paper                0.6          label\n",
       "1  alias-49384           yes  plastic               26.0     thermoform\n",
       "2  alias-79751           yes    paper                0.6          label\n",
       "3  alias-79751           yes    paper                0.6          label\n",
       "4  alias-79751           yes  plastic                8.0       flowpack"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the head\n",
    "display(packaging_weight_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5294c30a-81c7-4901-a8bc-24666744242a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ðŸ§¹ Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7f695be-2c24-4e94-b9de-8973a7fe94b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The following operations should happen to consider the dataset clean:\n",
    "1. We want the `has_packaging` field to be **boolean** type. Also, `NULL` should be converted to **False** values.\n",
    "2. Coherent behaviour: if `has_packaging` is **False**, then the unit_weight_grams should be zero, '0' (because it means that if an article has no packaging, then its pachaging weight is zero grams).\n",
    "3. We need categories, such as `paper`, `plastic` or `glass` to be mapped and cleaned\n",
    "4. Finally we want to delete duplicate entries according to a key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94d960b6-e20d-452f-b379-eb1d21024291",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a new DataFrame with the converted types\n",
    "packaging_weight_pd_conv = packaging_weight_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c852af85-d389-49b4-bc9e-cbb35835bce7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Field `has_packaging` boolean conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool\n",
      "has_packaging\n",
      "True     0.860619\n",
      "False    0.139381\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use a mapping to convert text strings to boolean-like values\n",
    "packaging_weight_pd_conv['has_packaging'] = packaging_weight_pd_conv['has_packaging'].map({\n",
    "    'yes': True,\n",
    "    'no': False\n",
    "})\n",
    "\n",
    "# Convert the object type to boolean for easier handling\n",
    "packaging_weight_pd_conv['has_packaging'] = packaging_weight_pd_conv['has_packaging'].astype(bool)\n",
    "\n",
    "# Fill missing values with False if applicable:\n",
    "packaging_weight_pd_conv['has_packaging'] = packaging_weight_pd_conv['has_packaging'].fillna(False)\n",
    "\n",
    "# check types\n",
    "print(packaging_weight_pd_conv['has_packaging'].dtypes)\n",
    "\n",
    "print(packaging_weight_pd_conv['has_packaging'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81510e8b-246b-4f69-9dfe-3d13cd939903",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Create a new `unit_weight_grams` with zeroes (0) for all the `has_packaging` False lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ce123e-bad6-470a-b3b2-5ab7945388b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column 'unit_weight_grams_clean' with the logic: if the has_packaging is False, then the weight is 0\n",
    "packaging_weight_pd_conv['unit_weight_grams_clean'] = packaging_weight_pd_conv.apply(\n",
    "    lambda row: 0 if not row['has_packaging'] else row['unit_weight_grams'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a64fb4e4-61d6-47c2-b94d-8b8158a0cce3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Clean Packaging Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d041da3f-728f-43ce-863d-17eb56f24523",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a new category column that contains only the values (paper, plastic, mixed, tetrapak, metal, glass) else \"unmapped\"\n",
    "# List of allowed categories\n",
    "valid_categories = ['paper', 'plastic', 'mixed', 'tetrapak', 'metal', 'glass']\n",
    "\n",
    "# Create a new column 'category_clean' with the specified logic\n",
    "packaging_weight_pd['category_clean'] = packaging_weight_pd['category'].apply(\n",
    "    lambda x: x if x in valid_categories else 'unmapped'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48053871-bf2e-42a3-b203-d53a1b92032a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Drop duplicate keys: `sku`-`has_packaging`-`category_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a77f30c1-63b0-4064-8b47-b503b8a9044f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped lines: 932\n",
      "Kept lines: 4040\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates based on the combination of 'sku', 'has_packaging', and 'category'\n",
    "# Keep the first occurrence of each combination\n",
    "packaging_weight_unique = packaging_weight_pd_conv.drop_duplicates(subset=['sku', 'has_packaging', 'category_clean'], keep='first')\n",
    "\n",
    "# Count the dropped lines\n",
    "print(\"Dropped lines: \" + str(len(packaging_weight_pd_conv) - len(packaging_weight_unique)))\n",
    "print(\"Kept lines: \" + str(len(packaging_weight_unique)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac52694-bd13-4d7b-bdfe-51d76f6316d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### -> Create the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48ae69a0-ec03-4eec-9da7-8f58069dc6b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>has_packaging</th>\n",
       "      <th>category_clean</th>\n",
       "      <th>unit_weight_grams_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alias-49384</td>\n",
       "      <td>True</td>\n",
       "      <td>paper</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alias-49384</td>\n",
       "      <td>True</td>\n",
       "      <td>plastic</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alias-79751</td>\n",
       "      <td>True</td>\n",
       "      <td>paper</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alias-79751</td>\n",
       "      <td>True</td>\n",
       "      <td>plastic</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alias-69325</td>\n",
       "      <td>True</td>\n",
       "      <td>paper</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sku  has_packaging category_clean  unit_weight_grams_clean\n",
       "0  alias-49384           True          paper                      0.6\n",
       "1  alias-49384           True        plastic                     26.0\n",
       "2  alias-79751           True          paper                      0.6\n",
       "4  alias-79751           True        plastic                      8.0\n",
       "6  alias-69325           True          paper                      0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define columns of final dataframe\n",
    "final_packaging_weight = packaging_weight_unique[['sku', 'has_packaging', 'category_clean', 'unit_weight_grams_clean']]\n",
    "display(final_packaging_weight.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ef97a3-8151-41c4-8597-91a25ea4f1c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ðŸ“¤ Calculate the Bill of Materials for `delivered_materials`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c91659a-96b9-4d16-9f9a-a33fe24873e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Get data from PDL source via SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The original pipeline was extracting data from the live tables in the DWH. The SQL query for this extraction has been published [here](https://github.com/werderame/werderame.github.io/blob/main/portfolio-projects/packaging_licencing_fee/notebooks/delivered_skus_df.sql) for reference, and cleaned of all sensitive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load demand data in a dataframe # delivered_skus_df\n",
    "file_path = '/Users/fil/Documents/my_projects/packaging_licencing_fee/datasets/delivered_skus_df_2024_11_20.csv'\n",
    "delivered_skus_df = pd.read_csv(file_path) # Execute the query and load the result into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64328 entries, 0 to 64327\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   dc                            64328 non-null  object\n",
      " 1   hf_month                      64328 non-null  object\n",
      " 2   hf_week                       64328 non-null  object\n",
      " 3   delivery_date                 64328 non-null  object\n",
      " 4   source                        64328 non-null  object\n",
      " 5   destination                   64328 non-null  object\n",
      " 6   sku                           64328 non-null  object\n",
      " 7   sku_category                  64328 non-null  object\n",
      " 8   randomized_delivery_quantity  64328 non-null  int64 \n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "delivered_skus_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71748af5-2617-4e71-9cbd-abeff1bef7ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ðŸ§¹ Clean and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data needs preparation:\n",
    "1. all **object** columns should replace empty values with **NULL**\n",
    "2. By knowing the HelloFresh operation, during discovery phase we noticed phase that the original source `delivered_skus_df` is lacking critical information for the final product, in particular: it is missing rows pertaining some of the materials being delivered to the customers. This is a shortcoming of the source which we want to address in the current section of the pipelind. The following items are missing from the source: <ins>Labels</ins> and <ins>Box Lids</ins> and represent secondary and thertiary packaging materials, respectively. We therefore:\n",
    "   - Add <ins>labels</ins> (also called meal-kit, or MK Labels) using the logic: for every row of 'mk_bag_data' add 1 meal-kit label\n",
    "   - Add <ins>Box Lids</ins> using the logic: each box has 1 lid. Notice that differently sized boxes have the same lid shape, here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a5783d0-f549-43b8-a135-88436dcc040c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Fields conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99d51541-4705-4293-8268-0b6542839997",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace all empty string values with strings in the dataframe\n",
    "string_columns = delivered_skus_df.select_dtypes(include=['object', 'string']).columns # Identify all string columns in the DataFrame\n",
    "delivered_skus_df[string_columns] = delivered_skus_df[string_columns].replace(\"\", np.nan) # Replace empty strings with null\n",
    "\n",
    "# Convert to date_time the `delivery_date`\n",
    "delivered_skus_df['delivery_date'] = pd.to_datetime(delivered_skus_df['delivery_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add missing lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae8b1639-5437-4998-be5d-68d84579c9d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.1 Create MK lable lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42ae1b1a-4c32-403e-abcb-044a58628ce5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total delivery_quantity for alias-33207: 5430978\n"
     ]
    }
   ],
   "source": [
    "# List of SKUs that require additional lines\n",
    "mk_label_target_lines = ['mk_bag_data']\n",
    "\n",
    "# Filter rows with target SKUs\n",
    "filtered_mk_label_df = delivered_skus_df[delivered_skus_df['source'].isin(mk_label_target_lines)]\n",
    "\n",
    "# Create the new rows by modifying the filtered rows\n",
    "mk_label_new_lines = filtered_mk_label_df.assign(\n",
    "    sku='alias-33207',\n",
    "    source='later_manipulation'\n",
    ")\n",
    "\n",
    "# Filter the DataFrame for the specific SKU\n",
    "filtered_df = mk_label_new_lines[mk_label_new_lines['sku'] == 'alias-33207']\n",
    "\n",
    "# Sum the delivery_quantity column, handling nulls automatically\n",
    "total_quantity = filtered_df['randomized_delivery_quantity'].sum()\n",
    "\n",
    "# Display the total sum\n",
    "print(f\"Total delivery_quantity for alias-33207: {total_quantity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bac409c-853b-43d4-9599-396a14450a64",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.2 Create BOX lid lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b47f1d-4ea5-46eb-81cf-3394ee538af7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total delivery_quantity for alias-98912: 901250\n"
     ]
    }
   ],
   "source": [
    "# List of SKUs that require additional lines\n",
    "box_lid_target_lines = ['alias-24862', 'alias-40634', 'alias-38167', 'alias-39686']\n",
    "\n",
    "# Filter rows with target SKUs\n",
    "filtered_box_lid_df = delivered_skus_df[delivered_skus_df['sku'].isin(box_lid_target_lines)]\n",
    "\n",
    "# Create the new rows by modifying the filtered rows\n",
    "box_lid_new_lines = filtered_box_lid_df.assign(\n",
    "    sku='alias-98912',\n",
    "    source='later_manipulation'\n",
    ")\n",
    "\n",
    "# Filter the DataFrame for the specific SKU\n",
    "filtered_df_2 = box_lid_new_lines[box_lid_new_lines['sku'] == 'alias-98912']\n",
    "\n",
    "# Sum the delivery_quantity column, handling nulls automatically\n",
    "total_quantity_2 = filtered_df_2['randomized_delivery_quantity'].sum()\n",
    "\n",
    "# Display the total sum\n",
    "print(f\"Total delivery_quantity for alias-98912: {total_quantity_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df828011-988f-4b52-be3c-82bbd003357c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### -> Append created lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f71746-5fbf-4e82-abe3-557058cdcbc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine the original DataFrame with the new rows from mk_label_new_lines\n",
    "manipulated_step1_delivered_skus_df = pd.concat([delivered_skus_df, mk_label_new_lines], ignore_index=True)\n",
    "\n",
    "# Combine the result with the new rows from box_lid_new_lines\n",
    "manipulated_step2_delivered_skus_df = pd.concat([manipulated_step1_delivered_skus_df, box_lid_new_lines], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee2838d-3c0e-4205-afc1-803ed309fcf6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64982 entries, 0 to 64981\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   dc                            64982 non-null  object        \n",
      " 1   hf_month                      64982 non-null  object        \n",
      " 2   hf_week                       64982 non-null  object        \n",
      " 3   delivery_date                 64982 non-null  datetime64[ns]\n",
      " 4   source                        64982 non-null  object        \n",
      " 5   destination                   64982 non-null  object        \n",
      " 6   sku                           64982 non-null  object        \n",
      " 7   sku_category                  64982 non-null  object        \n",
      " 8   randomized_delivery_quantity  64982 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(7)\n",
      "memory usage: 4.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display schema-like information for the DataFrame\n",
    "print(manipulated_step2_delivered_skus_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6cb927d-eba6-44d9-9af6-5be1b0c4afda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ðŸ“¤ Calculate the Bill of Materials for `disposals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The original pipeline was extracting data from the live tables in the DWH. The SQL query for this extraction has been published [here](https://github.com/werderame/werderame.github.io/blob/main/portfolio-projects/packaging_licencing_fee/notebooks/disposed_skus_df.sql) for reference, and cleaned of all sensitive information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b855fc0-d59f-4a22-8fa5-e9336500c7c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Get data from DWH source via SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load demand data in a dataframe # delivered_skus_df\n",
    "file_path = '/Users/fil/Documents/my_projects/packaging_licencing_fee/datasets/disposed_skus_df_2024_11_20.csv'\n",
    "disposed_skus_df = pd.read_csv(file_path) # Execute the query and load the result into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "240ccdf1-7a96-489e-a4d3-cf98a982dc18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5845 entries, 0 to 5844\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   dc                            5845 non-null   object\n",
      " 1   hf_month                      5845 non-null   object\n",
      " 2   hf_week                       5845 non-null   object\n",
      " 3   delivery_date                 5845 non-null   object\n",
      " 4   source                        5845 non-null   object\n",
      " 5   destination                   5845 non-null   object\n",
      " 6   sku                           5845 non-null   object\n",
      " 7   sku_category                  5845 non-null   object\n",
      " 8   randomized_delivery_quantity  5845 non-null   int64 \n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 411.1+ KB\n"
     ]
    }
   ],
   "source": [
    "disposed_skus_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Apart from the data type of the `delivery_date` this dataset is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Clean and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "disposed_skus_df['delivery_date'] = pd.to_datetime(disposed_skus_df['delivery_date'])\n",
    "print(disposed_skus_df['delivery_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”€ Final Data Preparation Steps: Merge Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62a67cfe-ad01-4b85-a767-b81086414ad4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Merge the `Delivered` and `Disposed` Materials = `total_deliveries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f02ccd1-1917-4ac0-859c-3bb032a2d81e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine the DataFrames using pandas concat\n",
    "total_delivered_skus_df = pd.concat([disposed_skus_df, manipulated_step2_delivered_skus_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2622582e-8b9a-4618-8c34-0387e67ece30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Merge the `total_deliveries` and `weights` dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a97faaca-68b8-43ec-a4ba-4fa5eb875846",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform a left join on the two DataFrames using the 'sku' column as the key\n",
    "delivered_weight_pd = total_delivered_skus_df.merge(final_packaging_weight, on='sku', how='left')\n",
    "\n",
    "# Add the calculated field of `delivered_weight` as the multiplication of quantities and weight per unit\n",
    "delivered_weight_pd['delivered_weight_grams'] = delivered_weight_pd['unit_weight_grams_clean'] * delivered_weight_pd['randomized_delivery_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc</th>\n",
       "      <th>hf_month</th>\n",
       "      <th>hf_week</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>sku</th>\n",
       "      <th>sku_category</th>\n",
       "      <th>randomized_delivery_quantity</th>\n",
       "      <th>has_packaging</th>\n",
       "      <th>category_clean</th>\n",
       "      <th>unit_weight_grams_clean</th>\n",
       "      <th>delivered_weight_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FI</td>\n",
       "      <td>2024-08</td>\n",
       "      <td>2024-W33</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>overkitting_waste</td>\n",
       "      <td>donation</td>\n",
       "      <td>alias-35165</td>\n",
       "      <td>C_05</td>\n",
       "      <td>408</td>\n",
       "      <td>True</td>\n",
       "      <td>plastic</td>\n",
       "      <td>1.350</td>\n",
       "      <td>550.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FI</td>\n",
       "      <td>2024-08</td>\n",
       "      <td>2024-W33</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>overkitting_waste</td>\n",
       "      <td>donation</td>\n",
       "      <td>alias-92488</td>\n",
       "      <td>C_08</td>\n",
       "      <td>62</td>\n",
       "      <td>True</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1.200</td>\n",
       "      <td>74.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FI</td>\n",
       "      <td>2024-08</td>\n",
       "      <td>2024-W34</td>\n",
       "      <td>2024-08-17</td>\n",
       "      <td>overkitting_waste</td>\n",
       "      <td>donation</td>\n",
       "      <td>alias-11082</td>\n",
       "      <td>C_06</td>\n",
       "      <td>218</td>\n",
       "      <td>True</td>\n",
       "      <td>plastic</td>\n",
       "      <td>1.000</td>\n",
       "      <td>218.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PI</td>\n",
       "      <td>2024-08</td>\n",
       "      <td>2024-W34</td>\n",
       "      <td>2024-08-17</td>\n",
       "      <td>overkitting_waste</td>\n",
       "      <td>donation</td>\n",
       "      <td>alias-56415</td>\n",
       "      <td>C_08</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>paper</td>\n",
       "      <td>1.386</td>\n",
       "      <td>23.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FI</td>\n",
       "      <td>2024-08</td>\n",
       "      <td>2024-W34</td>\n",
       "      <td>2024-08-17</td>\n",
       "      <td>overkitting_waste</td>\n",
       "      <td>donation</td>\n",
       "      <td>alias-62890</td>\n",
       "      <td>C_07</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>paper</td>\n",
       "      <td>8.000</td>\n",
       "      <td>208.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dc hf_month   hf_week delivery_date             source destination  \\\n",
       "0  FI  2024-08  2024-W33    2024-08-10  overkitting_waste    donation   \n",
       "1  FI  2024-08  2024-W33    2024-08-10  overkitting_waste    donation   \n",
       "2  FI  2024-08  2024-W34    2024-08-17  overkitting_waste    donation   \n",
       "3  PI  2024-08  2024-W34    2024-08-17  overkitting_waste    donation   \n",
       "4  FI  2024-08  2024-W34    2024-08-17  overkitting_waste    donation   \n",
       "\n",
       "           sku sku_category  randomized_delivery_quantity has_packaging  \\\n",
       "0  alias-35165         C_05                           408          True   \n",
       "1  alias-92488         C_08                            62          True   \n",
       "2  alias-11082         C_06                           218          True   \n",
       "3  alias-56415         C_08                            17          True   \n",
       "4  alias-62890         C_07                            26          True   \n",
       "\n",
       "  category_clean  unit_weight_grams_clean  delivered_weight_grams  \n",
       "0        plastic                    1.350                 550.800  \n",
       "1          mixed                    1.200                  74.400  \n",
       "2        plastic                    1.000                 218.000  \n",
       "3          paper                    1.386                  23.562  \n",
       "4          paper                    8.000                 208.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(delivered_weight_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â˜ï¸ Load the resulting `delivered_weight` to the Data Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f02e0417-e514-45cc-9812-fb5d60f011b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Push to Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally, in the original pipeline we would push the final dataframe to the Data Warehouse, allowing stakeholders to query the data, analyze it and pull it into Tableau. Here, we are simply leaving the code as reference and showing the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07441710-efcc-44b5-9f00-5c9990155cd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# delivered_weight_spark_df.write.mode(\"overwrite\").saveAsTable(\"<schema_name>.dach_delivered_packaging_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ac1a7c-2bff-4ecd-98c8-6a28df3a1ef1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Push missing skus to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> in the original pipeline we were pushing the 'missing skus' dataframe to the Google sheet containing the packaging weight, allowing the stakeholders to interactively update the packaging weight list. Such list, which we pull at the start of this pipeline, would thus be captured with the next run of the job and would complete the calculation of delivered packaging weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfbd6950-76a7-4eec-ab52-47ac8b000d4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Calculate the list of SKUs missing from the packaging_weight Google table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a5e8c3f-c57f-454d-9985-cdbd429c7ee6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing skus: 42\n"
     ]
    }
   ],
   "source": [
    "# create a df with the missing information\n",
    "missing_weight_skus = delivered_weight_pd[delivered_weight_pd['delivered_weight_grams'].isnull()]['sku']\n",
    "missing_weight_skus = missing_weight_skus.drop_duplicates()\n",
    "missing_weight_skus = missing_weight_skus.sort_values()\n",
    "print(\"missing skus: \" + str(len(missing_weight_skus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000    alias-11889\n",
       "4767     alias-14593\n",
       "15125    alias-16817\n",
       "11540    alias-18215\n",
       "11631    alias-24827\n",
       "12982    alias-26040\n",
       "6366     alias-33764\n",
       "11542    alias-35256\n",
       "22339    alias-39060\n",
       "15113    alias-39530\n",
       "Name: sku, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(missing_weight_skus.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of the pipeline"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "publish packaging weight",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
